{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Градиентные методы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция $f(x) = x_1^2 +x_2^2+x_1+x_2$, точка $x^{(0)} = (0, 0)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x[0]**2+x[1]**2+x[0]+x[1]\n",
    "def grad_f(x):\n",
    "    return np.array([2*x[0]+1, 2*x[1]+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Градиентный спуск с постоянным шагом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_descent_const_step(x = np.array([0, 0]), alpha = 0.001, epsilon = 0.05):\n",
    "    grad = grad_f(x)\n",
    "    n = 0\n",
    "    check = 0\n",
    "    while (np.linalg.norm(grad) > epsilon) or (check < 3):\n",
    "        x = x - alpha*grad\n",
    "        grad = grad_f(x)\n",
    "        n+=1\n",
    "        if (np.linalg.norm(grad) <= epsilon): check +=1\n",
    "    print(\"Градиентный спуск с постоянным шагом выполнил {} шагов\".format(n))\n",
    "    print(\"Точка с координатами х1 = {}, x2 = {}\".format(x[0], x[1]))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Градиентный спуст с постоянным шагом выполнил 17 шагов\n",
      "Точка с координатами х1 = -0.48874100093157374, x2 = -0.48874100093157374\n"
     ]
    }
   ],
   "source": [
    "x = grad_descent_const_step(alpha = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Градиентный спуск с заранее заданным шагом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_descent_series(x = np.array([0, 0]), epsilon = 0.05):\n",
    "    grad = grad_f(x)\n",
    "    n = 0\n",
    "    k = 1 \n",
    "    check = 0\n",
    "    while np.linalg.norm(grad) > epsilon or check < 3:\n",
    "        x = x - (1/k)*grad\n",
    "        grad = grad_f(x)\n",
    "        k+=1\n",
    "        n+=1\n",
    "        if (np.linalg.norm(grad) <= epsilon): check +=1\n",
    "    print(\"Градиентный спуст с заранее заданным шагом выполнил {} шагов\".format(n))\n",
    "    print(\"Точка с координатами х1 = {}, x2 = {}\".format(x[0], x[1]))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Градиентный спуст с заранее заданным шагом выполнил 4 шагов\n",
      "Точка с координатами х1 = -0.5, x2 = -0.5\n"
     ]
    }
   ],
   "source": [
    "a = grad_descent_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Градиентный спуск с дроблением шага"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_descent_step_splitting(x = np.array([0, 0]), alpha = 1, epsilon = 0.05, ksi = 0.5, lambda_d = 0.35):\n",
    "    grad = grad_f(x)\n",
    "    n = 0\n",
    "    n_alpha = 0\n",
    "    alpha_k = alpha\n",
    "    x_k0 = x\n",
    "    check = 0\n",
    "    while np.linalg.norm(grad) > epsilon or check < 3:\n",
    "        grad = grad_f(x_k0)\n",
    "        x_k1 = x_k0 - alpha_k*grad\n",
    "        while f(x_k1) - f(x_k0) > - alpha_k * ksi * (np.linalg.norm(grad)**2):\n",
    "            alpha_k *= lambda_d\n",
    "            x_k1 = x_k0 - alpha_k*grad\n",
    "            n_alpha+=1\n",
    "        x_k0 = x_k0 - alpha_k*grad\n",
    "        alpha_k = alpha\n",
    "        n+=1\n",
    "        if (np.linalg.norm(grad) <= epsilon): check +=1\n",
    "    x = x_k0\n",
    "    print(\"Градиентный спуст с дроблением шага выполнил {} шагов\".format(n))\n",
    "    print(\"Выполнено {} итераций дробления шага\".format(n_alpha))\n",
    "    print(\"Точка с координатами х1 = {}, x2 = {}\".format(x[0], x[1]))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Градиентный спуст с дроблением шага выполнил 6 шагов\n",
      "Выполнено 6 итераций дробления шага\n",
      "Точка с координатами х1 = -0.4996355, x2 = -0.4996355\n"
     ]
    }
   ],
   "source": [
    "a = grad_descent_step_splitting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метод наискорейшего градиентного спуска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimization_methods import passive_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, eps = 0.0001, 0.9999,  0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_descent_series(x = np.array([0, 0]), epsilon = 0.05):\n",
    "    grad = grad_f(x)\n",
    "    n = 0\n",
    "    check = 0\n",
    "    while np.linalg.norm(grad) > epsilon or check < 3:\n",
    "        alp = passive_search(f, x, grad, a, b, eps)\n",
    "        x = x - alp*grad\n",
    "        grad = grad_f(x)\n",
    "        n+=1\n",
    "        if (np.linalg.norm(grad) <= epsilon): check +=1\n",
    "    print(\"Метод наискорейшего градиентного спуска выполнил {} шагов\".format(n))\n",
    "    print(\"Точка с координатами х1 = {}, x2 = {}\".format(x[0], x[1]))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метод наискорейшего градиентного спуска выполнил 3 шагов\n",
      "Точка с координатами х1 = -0.499999996404, x2 = -0.499999996404\n"
     ]
    }
   ],
   "source": [
    "a = grad_descent_series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
